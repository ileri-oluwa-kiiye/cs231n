{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ileri-oluwa-kiiye/cs231n/blob/main/knn_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "re0QXoH5TlJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2775501-edc5-453c-cb45-210890e45474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup Complete\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "pd.plotting.register_matplotlib_converters()\n",
        "print(\"Setup Complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PPiLaaZ-5hIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a4bef04-c7ba-464a-d53d-f2b680e9669c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#Loading the cifar-10 dataset\n",
        "import tensorflow as tf\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vWMVYwTt6MjC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e18a2d1f-68c3-4676-96c4-3011dbac1490"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iqCvz8s0M9at"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#For the data preprocessing\n",
        "#Reshaping the data to be two dimensional\n",
        "def preprocess_data(X_train, X_test):\n",
        "  X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
        "  X_test_reshaped = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "  #using the standard scaler to enable a more uniform data\n",
        "  scaler = StandardScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
        "  X_test_scaled = scaler.transform(X_test_reshaped)\n",
        "\n",
        "  return X_train_scaled, X_test_scaled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pX68x0UtSOXR"
      },
      "outputs": [],
      "source": [
        "#Defining a parameter grid\n",
        "param_grid = {\n",
        "    'n_neighbors': [ 3, 5, 7, 9],  # different k values to try\n",
        "    'metric': ['manhattan', 'euclidean', 'minkowski'],  # different distance metrics\n",
        "    'weights': ['uniform', 'distance']  # weight function used in prediction\n",
        "}\n",
        "\n",
        "\n",
        "# Creating the KNN Classifier\n",
        "knn = KNeighborsClassifier()\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tewnqxCePBGd"
      },
      "outputs": [],
      "source": [
        "# Since the cifar dataset is large, let's use a part of it to perform the grid search\n",
        "train_subset_size = 5000\n",
        "test_subset_size = 1000\n",
        "\n",
        "X_train_subset = X_train[:train_subset_size]\n",
        "y_train_subset = y_train[:train_subset_size]\n",
        "\n",
        "X_test_subset = X_test[:test_subset_size]\n",
        "y_test_subset = y_test[:test_subset_size]\n",
        "\n",
        "X_train_preprocessed, X_test_preprocessed = preprocess_data(X_train_subset, X_test_subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8kfIl_-Matx",
        "outputId": "7e62472d-8c70-4766-c963-245123abd882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "\n",
            "Best params: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'distance'}\n",
            "\n",
            "Best Cross Validation Score: 0.31839999999999996\n"
          ]
        }
      ],
      "source": [
        "#grid search\n",
        "grid_search = GridSearchCV(\n",
        "    knn,\n",
        "    param_grid,\n",
        "    cv= cv,\n",
        "    n_jobs = 1,\n",
        "    verbose = 1,\n",
        "    scoring = 'accuracy',\n",
        "    return_train_score=True,\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train_preprocessed, y_train_subset.ravel())\n",
        "print(\"\\nBest params:\", grid_search.best_params_)\n",
        "print(\"\\nBest Cross Validation Score:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_euGbtKKZykw",
        "outputId": "2824128e-e960-48ba-b693-2a11512bf125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.46      0.42       103\n",
            "           1       0.92      0.13      0.24        89\n",
            "           2       0.26      0.50      0.34       100\n",
            "           3       0.33      0.16      0.21       103\n",
            "           4       0.18      0.42      0.25        90\n",
            "           5       0.29      0.14      0.19        86\n",
            "           6       0.25      0.24      0.24       112\n",
            "           7       0.55      0.22      0.31       102\n",
            "           8       0.42      0.72      0.53       106\n",
            "           9       0.69      0.23      0.34       109\n",
            "\n",
            "    accuracy                           0.33      1000\n",
            "   macro avg       0.43      0.32      0.31      1000\n",
            "weighted avg       0.43      0.33      0.31      1000\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[47  0 12  2  9  1  5  1 25  1]\n",
            " [ 8 12 12  4 15  1 10  0 23  4]\n",
            " [15  0 50  1 18  3  7  1  5  0]\n",
            " [ 9  1 21 16 22 11 18  1  4  0]\n",
            " [ 7  0 20  5 38  1  8  2  8  1]\n",
            " [ 6  0 19  6 22 12 11  6  4  0]\n",
            " [ 2  0 28  5 41  4 27  2  2  1]\n",
            " [ 4  0 21  5 27  4 10 22  7  2]\n",
            " [12  0  1  0 10  3  1  1 76  2]\n",
            " [10  0  9  5 14  2 12  4 28 25]]\n",
            "\n",
            "Top 3 parameter combinations:\n",
            "\n",
            "Rank 8:\n",
            "Parameters: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'distance'}\n",
            "Mean CV Score: 0.3184 (+/- 0.0250)\n",
            "\n",
            "Rank 4:\n",
            "Parameters: {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n",
            "Mean CV Score: 0.3178 (+/- 0.0241)\n",
            "\n",
            "Rank 6:\n",
            "Parameters: {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'distance'}\n",
            "Mean CV Score: 0.3168 (+/- 0.0282)\n"
          ]
        }
      ],
      "source": [
        "#get the best model and make predictions\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_preprocessed)\n",
        "\n",
        "\n",
        "# Print detailed evaluation metrics\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(y_test_subset, y_pred))\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test_subset, y_pred))\n",
        "\n",
        "# Print top 3 best parameter combinations\n",
        "print(\"\\nTop 3 parameter combinations:\")\n",
        "results_df = pd.DataFrame(grid_search.cv_results_)\n",
        "top_3 = results_df.nlargest(3, 'mean_test_score')\n",
        "for idx, row in top_3.iterrows():\n",
        "    print(f\"\\nRank {idx + 1}:\")\n",
        "    print(f\"Parameters: {row['params']}\")\n",
        "    print(f\"Mean CV Score: {row['mean_test_score']:.4f} (+/- {row['std_test_score']*2:.4f})\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBN8NCd6PdMXInAf15KEvO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}